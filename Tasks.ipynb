{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 09\n",
    "\n",
    "Integrantes:\n",
    "- Ricardo Méndez 21289\n",
    "- Sara Echeverría 21371\n",
    "- Melissa Pérez 21385\n",
    "- Francisco Castillo 21562\n",
    "\n",
    "Repositorio: https://github.com/MelissaPerez09/Laboratorio09-CC3045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01 - Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Diga cual es la diferencia entre Modelos de Markov y Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia es que los Modelos de Markov son modelos estocásticos que describen la secuencia de un evento probabilístico futuro que depende solo del evento actual. Mientras que los HMM son una extensión de los Modelos de Markov que incluyen estados ocultos, donde a pesar de no poder observarlos directamente se puede inferir de los datos \"visibles\". Entonces, la principal diferencia es que los HMM permiten modelas sistemas donde no todos los aspectos dle proceso son directamente observables. [(Jurafsky, 2024)](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigue qué son los factorial HMM (Hidden Markov Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son un tipo de modelo probabilístico utilizado para aprender modelos de series temporal. Son una generalización de los HMMs, en los que la variable oculta se factoriza en múltiples variables de estado y, por lo tanto, se representa de manera distribuida. En un FHMM, la variable oculta es representada por un conjunto de variables de estado, cada una de las cuales está asociada con una serie de probabilidades de transición, que dan la probabilidad de que cada componente se active dado el componente activo anterior. La salida del modelo en cada paso de tiempo depende de los valores de las variables de estado de todas las cadenas. \n",
    "\n",
    "Los FHMMs son instancias de modelos generativos de múltiples causas, ya que la salida del modelo en cada paso de tiempo depende de los valores de las variables de estado de todas las cadenas. Son también un caso especial de redes bayesianas dinámicas (DBNs). [(Ghahrmani, 1997)](https://www.ee.columbia.edu/~sfchang/course/svia-F03/papers/factorial-HMM-97.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo es utilizado en una técnica para inferir las secuencias de eventos. Estas pueden ser posiciones, estados en el tiempo, entre otras, siempre y cuando no sean evidentes (directamente observables). Dicha técnica cuenta con los siguientes pasos principales:\n",
    "\n",
    "- Forward: En este se calcula la probabilidad de llegar a cada posible estado oculto en cada punto del tiempo, basándose en la evidencia o datos observados hasta ese momento.\n",
    "- Backward: En este se calcula la probabilidad de los datos observados futuros partiendo de cada estado.\n",
    "- Combinación: En este se unen las probabilidades calculadas en los pasos anteriores, para estimar el estado más probable en cada momento, dado todo el conjunto de observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. En el algoritmo de Forward Backward, por qué es necesario el paso de Backward (puede escribir ejemplos o casos para responder esta pregunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por separado, el algoritmo Forward calcula la probabilidad de inicio a final y Backward de final a inicio. Es decir, que en un estado dado que no sea ni final ni inicio, Forward no toma en cuenta los estados futuros y Backward no toma en cuenta los estados pasados. Por ello su combinación es importante, para poder abarcar la secuencia completa y no solo un fragmento. [(Collins, S.F)](https://www.cs.columbia.edu/~mcollins/fb.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02 - Algoritmo Forward Backward en HMM\n",
    "\n",
    "En este ejercicio estamos ante un modelo meteorológico representado por un Modelo Oculto de Markov (HMM) con dos estados: \"Soleado\" y \"Lluvioso\". Queremos predecir el tiempo en un día determinado basándonos en las observaciones de si el día anterior estuvo soleado o lluvioso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.279880Z",
     "start_time": "2024-04-20T00:37:47.275181Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.307684Z",
     "start_time": "2024-04-20T00:37:47.299196Z"
    }
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = np.random.choice(self.states, p=[self.initial_prob[state] for state in self.states])\n",
    "\n",
    "        for _ in range(length):\n",
    "            sequence.append(current_state)\n",
    "            current_state = np.random.choice(self.states, p=[self.transition_prob[current_state][next_state] for next_state in self.states])\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    def forward(self, observations):\n",
    "        alpha = np.zeros((len(observations), len(self.states)))\n",
    "\n",
    "        # Initialize base cases (t = 0)\n",
    "        for i, state in enumerate(self.states):\n",
    "            alpha[0, i] = self.initial_prob[state] * self.emission_prob[state][observations[0]]\n",
    "\n",
    "        # Run forward algorithm for t > 0\n",
    "        for t in range(1, len(observations)):\n",
    "            for j, state in enumerate(self.states):\n",
    "                alpha[t, j] = sum(alpha[t-1, i] * self.transition_prob[self.states[i]][state] for i in range(len(self.states))) * self.emission_prob[state][observations[t]]\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, observations):\n",
    "        beta = np.zeros((len(observations), len(self.states)))\n",
    "\n",
    "        # Initialize base cases (T)\n",
    "        beta[len(observations) - 1] = np.ones(len(self.states))\n",
    "\n",
    "        # Run backward algorithm\n",
    "        for t in range(len(observations) - 2, -1, -1):\n",
    "            for i in range(len(self.states)):\n",
    "                beta[t, i] = sum(beta[t+1, j] * self.transition_prob[self.states[i]][self.states[j]] * self.emission_prob[self.states[j]][observations[t+1]] for j in range(len(self.states)))\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        alpha = self.forward(observations)\n",
    "        beta = self.backward(observations)\n",
    "        prob = (alpha * beta) / np.sum(alpha * beta, axis=1, keepdims=True)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definición de Estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.338333Z",
     "start_time": "2024-04-20T00:37:47.331760Z"
    }
   },
   "outputs": [],
   "source": [
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Sunny', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}}\n",
    "emission_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.344717Z",
     "start_time": "2024-04-20T00:37:47.340354Z"
    }
   },
   "outputs": [],
   "source": [
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.364517Z",
     "start_time": "2024-04-20T00:37:47.359774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia de estados generada: ['Rainy', 'Rainy', 'Rainy', 'Rainy', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Secuencia de estados generada: {hmm.generate_sequence(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.394855Z",
     "start_time": "2024-04-20T00:37:47.390067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades Forward:\n",
      "[[0.4     0.15   ]\n",
      " [0.304   0.051  ]\n",
      " [0.05272 0.06398]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probabilidades Forward:\\n{hmm.forward(observations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.411434Z",
     "start_time": "2024-04-20T00:37:47.407349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades Backward:\n",
      "[[0.222 0.186]\n",
      " [0.3   0.5  ]\n",
      " [1.    1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probabilidades Backward:\\n{hmm.backward(observations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:37:47.417815Z",
     "start_time": "2024-04-20T00:37:47.413437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades de estados:\n",
      "[[0.76092545 0.23907455]\n",
      " [0.781491   0.218509  ]\n",
      " [0.45175664 0.54824336]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probabilidades de estados:\\n{hmm.compute_state_probabilities(observations)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
