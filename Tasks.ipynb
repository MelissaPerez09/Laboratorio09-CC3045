{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 09\n",
    "\n",
    "Integrantes:\n",
    "- Ricardo Méndez 21289\n",
    "- Sara Echeverría 21371\n",
    "- Francisco Castillo 21562\n",
    "- Melissa Pérez 21385\n",
    "\n",
    "Repositorio: https://github.com/MelissaPerez09/Laboratorio09-CC3045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01 - Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Diga cual es la diferencia entre Modelos de Markov y Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia es que los Modelos de Markov son modelos estocásticos que describen la secuencia de un evento probabilístico futuro que depende solo del evento actual. Mientras que los HMM son una extensión de los Modelos de Markov que incluyen estados ocultos, donde a pesar de no poder observarlos directamente se puede inferir de los datos \"visibles\". Entonces, la principal diferencia es que los HMM permiten modelas sistemas donde no todos los aspectos dle proceso son directamente observables. [(Jurafsky, 2024)](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigue qué son los factorial HMM (Hidden Markov Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son un tipo de modelo probabilístico utilizado para aprender modelos de series temporal. Son una generalización de los HMMs, en los que la variable oculta se factoriza en múltiples variables de estado y, por lo tanto, se representa de manera distribuida. En un FHMM, la variable oculta es representada por un conjunto de variables de estado, cada una de las cuales está asociada con una serie de probabilidades de transición, que dan la probabilidad de que cada componente se active dado el componente activo anterior. La salida del modelo en cada paso de tiempo depende de los valores de las variables de estado de todas las cadenas. \n",
    "\n",
    "Los FHMMs son instancias de modelos generativos de múltiples causas, ya que la salida del modelo en cada paso de tiempo depende de los valores de las variables de estado de todas las cadenas. Son también un caso especial de redes bayesianas dinámicas (DBNs). [(Ghahrmani, 1997)](https://www.ee.columbia.edu/~sfchang/course/svia-F03/papers/factorial-HMM-97.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. En el algoritmo de Forward Backward, por qué es necesario el paso de Backward (puede escribir ejemplos o casos para responder esta pregunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02 - Algoritmo Forward Backward en HMM\n",
    "\n",
    "En este ejercicio estamos ante un modelo meteorológico representado por un Modelo Oculto de Markov (HMM) con dos estados: \"Soleado\" y \"Lluvioso\". Queremos predecir el tiempo en un día determinado basándonos en las observaciones de si el día anterior estuvo soleado o lluvioso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia Generada: ['Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny']\n",
      "\n",
      "Probabilidades Forward:\n",
      "[[0.4     0.15   ]\n",
      " [0.304   0.051  ]\n",
      " [0.05272 0.06398]]\n",
      "\n",
      "Probabilidades Backward:\n",
      "[[0.222 0.186]\n",
      " [0.3   0.5  ]\n",
      " [1.    1.   ]]\n",
      "\n",
      "Probabilidades de Estados:\n",
      "[[0.76092545 0.23907455]\n",
      " [0.781491   0.218509  ]\n",
      " [0.45175664 0.54824336]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = np.random.choice(self.states, p=[self.initial_prob[state] for state in self.states])\n",
    "\n",
    "        for _ in range(length):\n",
    "            sequence.append(current_state)\n",
    "            current_state = np.random.choice(self.states, p=[self.transition_prob[current_state][next_state] for next_state in self.states])\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    def forward(self, observations):\n",
    "        alpha = np.zeros((len(observations), len(self.states)))\n",
    "\n",
    "        # Initialize base cases (t = 0)\n",
    "        for i, state in enumerate(self.states):\n",
    "            alpha[0, i] = self.initial_prob[state] * self.emission_prob[state][observations[0]]\n",
    "\n",
    "        # Run forward algorithm for t > 0\n",
    "        for t in range(1, len(observations)):\n",
    "            for j, state in enumerate(self.states):\n",
    "                alpha[t, j] = sum(alpha[t-1, i] * self.transition_prob[self.states[i]][state] for i in range(len(self.states))) * self.emission_prob[state][observations[t]]\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, observations):\n",
    "        beta = np.zeros((len(observations), len(self.states)))\n",
    "\n",
    "        # Initialize base cases (T)\n",
    "        beta[len(observations) - 1] = np.ones(len(self.states))\n",
    "\n",
    "        # Run backward algorithm\n",
    "        for t in range(len(observations) - 2, -1, -1):\n",
    "            for i in range(len(self.states)):\n",
    "                beta[t, i] = sum(beta[t+1, j] * self.transition_prob[self.states[i]][self.states[j]] * self.emission_prob[self.states[j]][observations[t+1]] for j in range(len(self.states)))\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        alpha = self.forward(observations)\n",
    "        beta = self.backward(observations)\n",
    "        prob = (alpha * beta) / np.sum(alpha * beta, axis=1, keepdims=True)\n",
    "        return prob\n",
    "\n",
    "# Definición de parámetros\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Sunny', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}}\n",
    "emission_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}}\n",
    "\n",
    "# Creación de la instancia de HMM\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# Generar una secuencia de observaciones\n",
    "obs_sequence = hmm.generate_sequence(5)\n",
    "print(\"Secuencia Generada:\", obs_sequence)\n",
    "\n",
    "# Cálculo de probabilidades forward\n",
    "forward_probs = hmm.forward(observations)\n",
    "print(\"\\nProbabilidades Forward:\")\n",
    "print(forward_probs)\n",
    "\n",
    "# Cálculo de probabilidades backward\n",
    "backward_probs = hmm.backward(observations)\n",
    "print(\"\\nProbabilidades Backward:\")\n",
    "print(backward_probs)\n",
    "\n",
    "# Calcular probabilidades de estado\n",
    "state_probs = hmm.compute_state_probabilities(observations)\n",
    "print(\"\\nProbabilidades de Estados:\")\n",
    "print(state_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
